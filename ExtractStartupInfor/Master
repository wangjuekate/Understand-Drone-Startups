import html2text
import selenium
import time
import requests
import urllib2
import time
import json
import urllib2
import requests
import csv
import bs4
import MySQLdb as sql
import smtplib
import pprint
import xlrd
import csv
import string


#In Python
#Read FileID
book = open_workbook('C:/Users/Jue Wang/Downloads/leftout.xlsx')
for i in range(2933,8000):
    print i
    sheet1= book.sheet_by_index(0)
    address =''.join(str(sheet1.cell(i,0).value))
    print address
    website = 'https://www.regulations.gov'+'/document?D=FAA-'+address +'-0001'
    browser.get(website)
    time.sleep(5)

#Extract Name from the website
firmname = browser.find_element_by_xpath('//div[@class="GIY1LSJCID"]/h1').text.encode('utf-8')
#Extract Name from the website
firmname = firmname.split('-')[0]

#use Google API to get the index page of the startup

#check whether the website is valid
firm ='https://www.sensefly.com/'

#write out the information
csvfile = open( 'C:\Users\Jue Wang\Downloads\indexpageinfor.csv', 'wb')
fieldnames = ['DocID', 'firmname','indexpage']
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
writer.writeheader()

#use wayback machine to extract the website at 201606
time = '201603'
url = 'https://web.archive.org/web/'+ time + '/'+firm
page =urllib2.urlopen(url)
f=page.read().decode('utf-8')
html = f
h = html2text.HTML2Text()
h.ignore_links = True


#write out to files, name as FileID with time 
file = 'C:/Users/wang547/'+fileID +time+'.txt'
print file
out = open (file,'w+')
out.write(h.handle(html).encode('utf-8'))



# In R to analyze the files
#extract time range of the website
#check keywords from the file
